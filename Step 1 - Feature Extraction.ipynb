{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature extraction\n",
    "### _TODO_\n",
    "This notebook continues the codifies the capabilities discussed in this [blog post](https://8081-dot-3124631-dot-devshell.appspot.com/). In a nutshell, it uses the pre-trained inception model as a starting point and then uses transfer learning to train it further on additional, customer-specific images. For explanation, simple flower images are used. Compared to training from scratch, the time and costs are drastically reduced.\n",
    "\n",
    "This notebook does preprocessing, training and prediction by calling CloudML API instead of running them in the Datalab container.  The purpose of local work is to do some initial prototyping and debugging on small scale data - often by taking a suitable (say 0.1 - 1%) sample of the full data. The same basic steps can then be repeated with much larger datasets in cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import apache_beam as beam\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "from apache_beam.io import tfrecordio\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "project_id = datalab_project_id()\n",
    "bucket = 'gs://candies-{}-dantest'.format(project_id)\n",
    "preprocess_dir = '{}/candies_preprocessed_cloud'.format(bucket)\n",
    "model_dir = '{}/candies_model_cloud'.format(bucket)\n",
    "staging_dir = '{}/staging'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil mb $bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pipeline transformations\n",
    "Code the pipeline transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Extract images and labels from CSV\n",
    "Extracts (uri, label_ids) tuples from CSV rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ExtractLabelIdsDoFn(beam.DoFn):\n",
    "  \"\"\"Extracts (uri, label_ids) tuples from CSV rows.\n",
    "  \"\"\"\n",
    "\n",
    "  def start_bundle(self, context=None):\n",
    "    self.label_to_id_map = {}\n",
    "\n",
    "  def process(self, element, all_labels):\n",
    "    all_labels = list(all_labels)\n",
    "    # DataFlow cannot garuantee the order of the labels when materializing it.\n",
    "    # The labels materialized and consumed by training may not be in the same order\n",
    "    # as the one used in preprocessing. So we need to sort it in both preprocessing\n",
    "    # and training so the order matches.\n",
    "    all_labels.sort()\n",
    "    if not self.label_to_id_map:\n",
    "      for i, label in enumerate(all_labels):\n",
    "        label = label.strip()\n",
    "        if label:\n",
    "          self.label_to_id_map[label] = i\n",
    "\n",
    "    # Row format is:\n",
    "    # image_uri,label_id\n",
    "    if not element:\n",
    "      return\n",
    "\n",
    "    uri = element['image_url']\n",
    "    label_id = self.label_to_id_map[element['label'].strip()]\n",
    "    yield uri, label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert images to JPEG\n",
    "Read files from GCS and convert images to JPEG format. We do this even for JPEG images to remove variations such as different number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ReadImageAndConvertToJpegDoFn(beam.DoFn):\n",
    "\n",
    "  def process(self, element):\n",
    "    \n",
    "    import cStringIO\n",
    "    from PIL import Image\n",
    "    from tensorflow.python.lib.io import file_io as tf_file_io\n",
    "\n",
    "    uri, label_id = element\n",
    "    try:\n",
    "      with tf_file_io.FileIO(uri, 'r') as f:\n",
    "        img = Image.open(f).convert('RGB')\n",
    "    # A variety of different calling libraries throw different exceptions here.\n",
    "    # They all correspond to an unreadable file so we treat them equivalently.\n",
    "    # pylint: disable broad-except\n",
    "    except Exception as e:\n",
    "      logging.exception('Error processing image %s: %s', uri, str(e))\n",
    "      return\n",
    "\n",
    "    # Convert to desired format and output.\n",
    "    output = cStringIO.StringIO()\n",
    "    img.save(output, 'jpeg')\n",
    "    image_bytes = output.getvalue()\n",
    "    yield uri, label_id, image_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Extract features from images\n",
    "\n",
    "Embeds image bytes and labels, stores them in tensorflow.Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TFExampleFromImageDoFn(beam.DoFn):\n",
    "  \"\"\"Embeds image bytes and labels, stores them in tensorflow.Example.\n",
    "\n",
    "  (uri, label_ids, image_bytes) -> (tensorflow.Example).\n",
    "\n",
    "  Output proto contains 'label', 'image_uri' and 'embedding'.\n",
    "  The 'embedding' is calculated by feeding image into input layer of image\n",
    "  neural network and reading output of the bottleneck layer of the network.\n",
    "\n",
    "  Attributes:\n",
    "    image_graph_uri: an uri to gcs bucket where serialized image graph is\n",
    "                     stored.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, checkpoint_path):\n",
    "    import tensorflow as tf\n",
    "    self._tf = tf\n",
    "    self._tf_train = tf.train\n",
    "    self.tf_session = None\n",
    "    self.graph = None\n",
    "    self.preprocess_graph = None\n",
    "    self._checkpoint_path = checkpoint_path\n",
    "\n",
    "  def start_bundle(self, context=None):\n",
    "    # There is one tensorflow session per instance of TFExampleFromImageDoFn.\n",
    "    # The same instance of session is re-used between bundles.\n",
    "    # Session is closed by the destructor of Session object, which is called\n",
    "    # when instance of TFExampleFromImageDoFn() is destructed.\n",
    "    import mltoolbox.image.classification._preprocess as preprocess\n",
    "    if not self.graph:\n",
    "      self.graph = self._tf.Graph()\n",
    "      self.tf_session = self._tf.InteractiveSession(graph=self.graph)\n",
    "      with self.graph.as_default():\n",
    "        self.preprocess_graph = preprocess.EmbeddingsGraph(self.tf_session, self._checkpoint_path)\n",
    "\n",
    "  def finish_bundle(self, context=None):\n",
    "    if self.tf_session is not None:\n",
    "      self.tf_session.close()\n",
    "\n",
    "  def process(self, element):\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "      return self._tf_train.Feature(bytes_list=self._tf_train.BytesList(value=value))\n",
    "\n",
    "    def _float_feature(value):\n",
    "      return self._tf_train.Feature(float_list=self._tf_train.FloatList(value=value))\n",
    "\n",
    "    uri, label_id, image_bytes = element\n",
    "\n",
    "    try:\n",
    "      embedding = self.preprocess_graph.calculate_embedding(image_bytes)\n",
    "    except self._tf.errors.InvalidArgumentError as e:\n",
    "      logging.warning('Could not encode an image from %s: %s', uri, str(e))\n",
    "      return\n",
    "\n",
    "    features = self._tf_train.Features(\n",
    "      feature={\n",
    "        'image_uri': _bytes_feature([str(uri)]),\n",
    "        'embedding': _float_feature(embedding.ravel().tolist())\n",
    "      })\n",
    "    example = self._tf_train.Example(features=features)\n",
    "    example.features.feature['label'].int64_list.value.append(label_id)\n",
    "\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Split data into training and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TrainEvalSplitPartitionFn(beam.PartitionFn):\n",
    "  \"\"\"Split train and eval data.\"\"\"\n",
    "  def partition_for(self, element, num_partitions):\n",
    "    import random\n",
    "    return 1 if random.random() > 0.7 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save features in TFRecordIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ExampleProtoCoder(beam.coders.Coder):\n",
    "  \"\"\"A coder to encode and decode TensorFlow Example objects.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    import tensorflow as tf\n",
    "    self._tf_train = tf.train\n",
    "\n",
    "  def encode(self, example_proto):\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "  def decode(self, serialized_str):\n",
    "    example = self._tf_train.Example()\n",
    "    example.ParseFromString(serialized_str)\n",
    "    return example\n",
    "\n",
    "\n",
    "class SaveFeatures(beam.PTransform):\n",
    "  \"\"\"Save Features in a TFRecordIO format.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, file_path_prefix):\n",
    "    super(SaveFeatures, self).__init__('SaveFeatures')\n",
    "    self._file_path_prefix = file_path_prefix\n",
    "\n",
    "  def expand(self, features):\n",
    "    return (features |\n",
    "            'Write features' >> tfrecordio.WriteToTFRecord(file_path_prefix=self._file_path_prefix,\n",
    "                                                           file_name_suffix='.tfrecord.gz',\n",
    "                                                           coder=ExampleProtoCoder()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the pipeline\n",
    "\n",
    "Boilerplate code to create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_DEFAULT_CHECKPOINT_GSURL = 'gs://cloud-ml-data/img/flower_photos/inception_v3_2016_08_28.ckpt'\n",
    "\n",
    "def create_pipeline(train_dataset, output_dir, project, pipeline_option):\n",
    "  \"\"\"Create the Dataflow pipeline.\"\"\"\n",
    "  import csv\n",
    "\n",
    "  job_name = ('preprocess-image-classification-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "  options = {\n",
    "      'staging_location': os.path.join(output_dir, 'tmp', 'staging'),\n",
    "      'temp_location': os.path.join(output_dir, 'tmp'),\n",
    "      'job_name': job_name,\n",
    "      'project': project,\n",
    "      'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "      'no_save_main_session': True\n",
    "  }\n",
    "  if pipeline_option is not None:\n",
    "    options.update(pipeline_option)\n",
    "\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "  p = beam.Pipeline('DataflowRunner', options=opts)\n",
    "  \n",
    "  labeled_images = (p |\n",
    "                    'Read from CSV' >> beam.io.ReadFromText(train_dataset, strip_trailing_newlines=True) |\n",
    "                    'Create Dict from CSV' >> beam.Map(lambda line: csv.DictReader([line], fieldnames=['image_url', 'label']).next()))  \n",
    "  labels = (labeled_images |\n",
    "            'Parse input for labels' >> beam.Map(lambda x: str(x['label'])) |\n",
    "            'Combine labels' >> beam.transforms.combiners.Count.PerElement() |\n",
    "            'Get labels' >> beam.Map(lambda label_count: label_count[0]))  \n",
    "  \n",
    "  preprocessed = (labeled_images |\n",
    "                 'Extract label ids' >> beam.ParDo(ExtractLabelIdsDoFn(), beam.pvalue.AsIter(labels)) |\n",
    "                 'Read and convert to JPEG' >> beam.ParDo(ReadImageAndConvertToJpegDoFn()) |\n",
    "                 'Embed and make TFExample' >> beam.ParDo(TFExampleFromImageDoFn(_DEFAULT_CHECKPOINT_GSURL)))\n",
    "  \n",
    "  train_preprocessed, eval_preprocessed = (preprocessed |\n",
    "                                           'Random partition' >> beam.Partition(TrainEvalSplitPartitionFn(), 2))  \n",
    "  \n",
    "  output_train_path = os.path.join(output_dir, job_name, 'train')\n",
    "  output_eval_path = os.path.join(output_dir, job_name, 'eval')\n",
    "  labels_file = os.path.join(output_dir, job_name, 'labels')\n",
    "  \n",
    "  labels_save = (labels |\n",
    "                 'Write labels' >> beam.io.textio.WriteToText(labels_file, shard_name_template=''))\n",
    "  train_save = (train_preprocessed |\n",
    "                'Save train to disk' >> SaveFeatures(output_train_path))\n",
    "  eval_save = (eval_preprocessed |\n",
    "               'Save eval to disk' >> SaveFeatures(output_eval_path))\n",
    "  \n",
    "  output_latest_file = os.path.join(output_dir, 'latest')\n",
    "  ([eval_save, train_save, labels_save] |\n",
    "   'Wait for train eval saving' >> beam.Flatten() |\n",
    "   'Fixed One' >> beam.transforms.combiners.Sample.FixedSizeGlobally(1) |\n",
    "   beam.Map(lambda path: job_name) |\n",
    "   'WriteLatest' >> beam.io.textio.WriteToText(output_latest_file, shard_name_template=''))\n",
    "  \n",
    "  return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run the pipeline \n",
    "Boilerplate code to run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_TF_GS_URL = 'gs://cloud-datalab/deploy/tf/tensorflow-1.2.0-cp27-none-linux_x86_64.whl'\n",
    "_PROTOBUF_GS_URL = 'gs://cloud-datalab/deploy/tf/protobuf-3.1.0-py2.py3-none-any.whl'\n",
    "\n",
    "\n",
    "def run_pipeline(train_dataset, output_dir, project, pipeline_options=None):\n",
    "  \"\"\"Preprocess data in Cloud with DataFlow.\"\"\"\n",
    "  import mltoolbox.image.classification._util as util\n",
    "  from tensorflow.python.lib.io import file_io\n",
    "  \n",
    "  tmpdir = tempfile.mkdtemp()\n",
    "  original_level = logging.getLogger().getEffectiveLevel()\n",
    "  logging.getLogger().setLevel(logging.ERROR)\n",
    "  try:\n",
    "    # Workaround for DataFlow 2.0, which doesn't work well with extra packages in GCS.\n",
    "    # Remove when the issue is fixed and new version of DataFlow is included in Datalab.\n",
    "    staging_package_url = util.repackage_to_staging(output_dir)\n",
    "    extra_packages = [staging_package_url, _TF_GS_URL, _PROTOBUF_GS_URL]\n",
    "    local_packages = [os.path.join(tmpdir, os.path.basename(p)) for p in extra_packages]\n",
    "    for source, dest in zip(extra_packages, local_packages):\n",
    "      file_io.copy(source, dest, overwrite=True)\n",
    "    if pipeline_options is None:\n",
    "      additional_options = {}\n",
    "    else:\n",
    "      additional_options = dict(pipeline_options)\n",
    "    additional_options['extra_packages'] = local_packages\n",
    "    \n",
    "    p = create_pipeline(train_dataset, output_dir, project, additional_options)\n",
    "    job_results = p.run()\n",
    "    job_results.wait_until_finish()\n",
    "  finally:\n",
    "    shutil.rmtree(tmpdir)\n",
    "    logging.getLogger().setLevel(original_level)\n",
    "    \n",
    "  dataflow_url = 'https://console.developers.google.com/dataflow?project=%s' % project\n",
    "  html = 'Job \"%s\" submitted.' % p.options.get_all_options()['job_name']\n",
    "  html += '<p>Click <a href=\"%s\" target=\"_blank\">here</a> to track preprocessing job. <br/>' % dataflow_url\n",
    "  IPython.display.display_html(html, raw=True)\n",
    "  #return google.datalab.utils.DataflowJob(job_results)\n",
    "\n",
    "\n",
    "train_set = 'gs://candies-ml/dataset/metadata/train_candies560.csv'\n",
    "preprocess_job = run_pipeline(train_dataset=train_set,\n",
    "                              output_dir=preprocess_dir,\n",
    "                              project=project_id,\n",
    "                              pipeline_options={'num_workers': 10})\n",
    "#preprocess_job.wait() # Alternatively, you can query the job status by train_job.state. The wait() call blocks the notebook execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
