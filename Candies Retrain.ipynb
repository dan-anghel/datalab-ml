{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Retrain\n",
    "This tutorial demonstrates the Transfer Learning technique applied to creating an image classifier capable of recognizing candies. It uses the pre-trained [MobileNet](https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html) Convolutional Neural Network with an input image resolution of 224px and a model 50% the size of the largest MobileNet network. MobileNet reusable components (modules) are availabe on [TensorFlow Hub](https://www.tensorflow.org/hub/modules/image) along with modules of other pre-trained image recognition networks like Inception and ResNet.\n",
    "\n",
    "This tutorial is heavily inspired from the [TensorFlow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets) codelab and the source is an adaptation of the code provided in the [retrain.py](https://github.com/googlecodelabs/tensorflow-for-poets-2/blob/master/scripts/retrain.py) file of the aforementioned codelab. A more explanation rich version of this codelab is available as a [TensorFlow tutorial on Transfer Learning](https://www.tensorflow.org/tutorials/image_retraining).\n",
    "\n",
    "The source code of this tutorial is available on [Github](https://github.com/dan-anghel/datalab-ml)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preliminaries\n",
    "Please run the code in the box below to import all required modules and to create the **gs://[GCP_PROJECT_ID]-image-classifier** bucket in which the trained model will be stored.\n",
    "<p>\n",
    "Display the content of the box if you want to have a closer look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from six.moves import urllib\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "project_id = datalab_project_id()\n",
    "bucket = 'gs://%s-image-classifier' % project_id\n",
    "!gsutil mb $bucket\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize the data\n",
    "We will train our classifier to recognize images of the following classes of candies: almondjoy, bounty, dove, mars, milkyway, snickers, threemusketeers, twix. Let's have a look at a few samples from the dataset.\n",
    "<p>\n",
    "Please run the code in the box below to display 4 random samples of images of each class. Run the code multiple times to get a sense of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "from cStringIO import StringIO\n",
    "from tensorflow.python.lib.io import file_io as tf_file_io\n",
    "\n",
    "\n",
    "def resize_image(image_str_tensor):\n",
    "  \"\"\"Decodes jpeg string, resizes it and re-encode it to jpeg.\"\"\"\n",
    "  import tensorflow as tf\n",
    "  \n",
    "  # These constants are set by Inception v3's expectations.\n",
    "  height = 299\n",
    "  width = 299\n",
    "  channels = 3\n",
    "\n",
    "  image = tf.image.decode_jpeg(image_str_tensor, channels=channels)\n",
    "  # Note resize expects a batch_size, but tf_map supresses that index,\n",
    "  # thus we have to expand then squeeze.  Resize returns float32 in the\n",
    "  # range [0, uint8_max]\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  image = tf.image.resize_bilinear(image, [height, width], align_corners=False)\n",
    "  image = tf.squeeze(image, squeeze_dims=[0])\n",
    "  image = tf.cast(image, dtype=tf.uint8)\n",
    "  image = tf.image.encode_jpeg(image, quality=100)\n",
    "  return image\n",
    "\n",
    "\n",
    "def display_images(image_files):\n",
    "  \"\"\"Predict using a deployed (online) model.\"\"\"\n",
    "  \n",
    "  images = []\n",
    "  for image_file in image_files:\n",
    "    with tf_file_io.FileIO(image_file, 'r') as ff:\n",
    "      images.append(ff.read())\n",
    "\n",
    "  # To resize, run a tf session so we can reuse 'decode_and_resize()'\n",
    "  # which is used in prediction graph. This makes sure we don't lose\n",
    "  # any quality in prediction, while decreasing the size of the images\n",
    "  # submitted to the model over network.\n",
    "  image_str_tensor = tf.placeholder(tf.string, shape=[None])\n",
    "  image = tf.map_fn(resize_image, image_str_tensor, back_prop=False)\n",
    "  feed_dict = collections.defaultdict(list)\n",
    "  feed_dict[image_str_tensor.name] = images\n",
    "  with tf.Session() as sess:\n",
    "    images_resized = sess.run(image, feed_dict=feed_dict)\n",
    "\n",
    "  html = '<table>'\n",
    "  for i, image in enumerate(images_resized):\n",
    "    encoded_image = base64.b64encode(image)\n",
    "    image_html = \"<td><img src='data:image/jpg;base64, %s'></td>\" % encoded_image\n",
    "    if i % 4 == 0:\n",
    "      html = html + '<tr>'\n",
    "    html = html + image_html\n",
    "    if i % 4 == 3:\n",
    "      html = html + '</tr>'\n",
    "  #IPython.display.display(IPython.display.Image(data=image))\n",
    "  html = html + '</table>'\n",
    "  IPython.display.display(IPython.display.HTML(html))\n",
    "\n",
    "\n",
    "train_dataset = 'gs://candies-ml/dataset/v1/metadata/train_candies560.csv'\n",
    "%storage read --object $train_dataset --variable text\n",
    "df = pd.read_csv(StringIO(text), names=['image_uri', 'category'])\n",
    "\n",
    "images = []\n",
    "categories = df['category'].drop_duplicates().values\n",
    "for category in categories:\n",
    "  image_uris = df.loc[df['category'] == category]\n",
    "  images.extend(image_uris['image_uri'].sample(n=4, replace=False).values)\n",
    "display_images(images)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup temporary folders\n",
    "Please run the code in the box below to make sure all temporary folders required during the model training are created, most notably the summaries folder that will store data for TensorBoard visualisation of the accuracy and loss functions durint training.\n",
    "<p>\n",
    "Display the content of the box if you want to have a closer look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir_exists(dir_name):\n",
    "  \"\"\"Makes sure the folder exists on disk.\n",
    "\n",
    "  Args:\n",
    "    dir_name: Path string to the folder we want to create.\n",
    "  \"\"\"\n",
    "  if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "\n",
    "def prepare_file_system(summaries_dir,\n",
    "                        intermediate_output_graphs_dir,\n",
    "                        intermediate_store_frequency):\n",
    "  # Setup the directory we'll write summaries to for TensorBoard\n",
    "  if tf.gfile.Exists(summaries_dir):\n",
    "    tf.gfile.DeleteRecursively(summaries_dir)\n",
    "  tf.gfile.MakeDirs(summaries_dir)\n",
    "  if intermediate_store_frequency > 0:\n",
    "    ensure_dir_exists(intermediate_output_graphs_dir)\n",
    "  return\n",
    "\n",
    "# Prepare necessary directories  that can be used during training\n",
    "summaries_dir='tf_files/training_summaries/mobilenet_0.50_224'\n",
    "intermediate_output_graphs_dir='/tmp/intermediate_graph/'\n",
    "intermediate_store_frequency=0\n",
    "prepare_file_system(summaries_dir=summaries_dir,\n",
    "                    intermediate_output_graphs_dir=intermediate_output_graphs_dir,\n",
    "                    intermediate_store_frequency=intermediate_store_frequency)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Download the model\n",
    "Please run the code in the box below to download the MobileNet model and to load it as a TensorFlow graph for further processing. As mentioned previously, we will use int hir tutorial a MobileNet model with an input image resolution of 224px and a model size 50% of the size of the largest MobileNet network.\n",
    "<p>\n",
    "Display the content of the box if you want to have a closer look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_model_info(architecture):\n",
    "  \"\"\"Given the name of a model architecture, returns information about it.\n",
    "\n",
    "  There are different base image recognition pretrained models that can be\n",
    "  retrained using transfer learning, and this function translates from the name\n",
    "  of a model to the attributes that are needed to download and train with it.\n",
    "\n",
    "  Args:\n",
    "    architecture: Name of a model architecture.\n",
    "\n",
    "  Returns:\n",
    "    Dictionary of information about the model, or None if the name isn't\n",
    "    recognized\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If architecture name is unknown.\n",
    "  \"\"\"\n",
    "  architecture = architecture.lower()\n",
    "  if architecture == 'inception_v3':\n",
    "    # pylint: disable=line-too-long\n",
    "    data_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "    # pylint: enable=line-too-long\n",
    "    bottleneck_tensor_name = 'pool_3/_reshape:0'\n",
    "    bottleneck_tensor_size = 2048\n",
    "    input_width = 299\n",
    "    input_height = 299\n",
    "    input_depth = 3\n",
    "    resized_input_tensor_name = 'Mul:0'\n",
    "    model_file_name = 'classify_image_graph_def.pb'\n",
    "    input_mean = 128\n",
    "    input_std = 128\n",
    "  elif architecture.startswith('mobilenet_'):\n",
    "    parts = architecture.split('_')\n",
    "    if len(parts) != 3 and len(parts) != 4:\n",
    "      tf.logging.error(\"Couldn't understand architecture name '%s'\",\n",
    "                       architecture)\n",
    "      return None\n",
    "    version_string = parts[1]\n",
    "    if (version_string != '1.0' and version_string != '0.75' and\n",
    "        version_string != '0.50' and version_string != '0.25'):\n",
    "      tf.logging.error(\n",
    "          \"\"\"\"The Mobilenet version should be '1.0', '0.75', '0.50', or '0.25',\n",
    "  but found '%s' for architecture '%s'\"\"\",\n",
    "          version_string, architecture)\n",
    "      return None\n",
    "    size_string = parts[2]\n",
    "    if (size_string != '224' and size_string != '192' and\n",
    "        size_string != '160' and size_string != '128'):\n",
    "      tf.logging.error(\n",
    "          \"\"\"The Mobilenet input size should be '224', '192', '160', or '128',\n",
    " but found '%s' for architecture '%s'\"\"\",\n",
    "          size_string, architecture)\n",
    "      return None\n",
    "    if len(parts) == 3:\n",
    "      is_quantized = False\n",
    "    else:\n",
    "      if parts[3] != 'quantized':\n",
    "        tf.logging.error(\n",
    "            \"Couldn't understand architecture suffix '%s' for '%s'\", parts[3],\n",
    "            architecture)\n",
    "        return None\n",
    "      is_quantized = True\n",
    "    data_url = 'http://download.tensorflow.org/models/mobilenet_v1_'\n",
    "    data_url += version_string + '_' + size_string + '_frozen.tgz'\n",
    "    bottleneck_tensor_name = 'MobilenetV1/Predictions/Reshape:0'\n",
    "    bottleneck_tensor_size = 1001\n",
    "    input_width = int(size_string)\n",
    "    input_height = int(size_string)\n",
    "    input_depth = 3\n",
    "    resized_input_tensor_name = 'input:0'\n",
    "    if is_quantized:\n",
    "      model_base_name = 'quantized_graph.pb'\n",
    "    else:\n",
    "      model_base_name = 'frozen_graph.pb'\n",
    "    model_dir_name = 'mobilenet_v1_' + version_string + '_' + size_string\n",
    "    model_file_name = os.path.join(model_dir_name, model_base_name)\n",
    "    input_mean = 127.5\n",
    "    input_std = 127.5\n",
    "  else:\n",
    "    tf.logging.error(\"Couldn't understand architecture name '%s'\", architecture)\n",
    "    raise ValueError('Unknown architecture', architecture)\n",
    "\n",
    "  return {\n",
    "      'data_url': data_url,\n",
    "      'bottleneck_tensor_name': bottleneck_tensor_name,\n",
    "      'bottleneck_tensor_size': bottleneck_tensor_size,\n",
    "      'input_width': input_width,\n",
    "      'input_height': input_height,\n",
    "      'input_depth': input_depth,\n",
    "      'resized_input_tensor_name': resized_input_tensor_name,\n",
    "      'model_file_name': model_file_name,\n",
    "      'input_mean': input_mean,\n",
    "      'input_std': input_std,\n",
    "  }\n",
    "\n",
    "def maybe_download_and_extract(data_url, model_dir):\n",
    "  \"\"\"Download and extract model tar file.\n",
    "\n",
    "  If the pretrained model we're using doesn't already exist, this function\n",
    "  downloads it from the TensorFlow.org website and unpacks it into a directory.\n",
    "\n",
    "  Args:\n",
    "    data_url: Web location of the tar file containing the pretrained model.\n",
    "  \"\"\"\n",
    "  dest_directory = model_dir\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = data_url.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                       (filename,\n",
    "                        float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    tf.logging.info('Successfully downloaded {}, {} bytes.'.format(filename, statinfo.st_size))\n",
    "  tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "  \n",
    "def create_model_graph(model_info, model_dir):\n",
    "  \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "\n",
    "  Args:\n",
    "    model_info: Dictionary containing information about the model architecture.\n",
    "\n",
    "  Returns:\n",
    "    Graph holding the trained Inception network, and various tensors we'll be\n",
    "    manipulating.\n",
    "  \"\"\"\n",
    "  with tf.Graph().as_default() as graph:\n",
    "    model_path = os.path.join(model_dir, model_info['model_file_name'])\n",
    "    with gfile.FastGFile(model_path, 'rb') as f:\n",
    "      graph_def = tf.GraphDef()\n",
    "      graph_def.ParseFromString(f.read())\n",
    "      bottleneck_tensor, resized_input_tensor = (tf.import_graph_def(\n",
    "          graph_def,\n",
    "          name='',\n",
    "          return_elements=[\n",
    "              model_info['bottleneck_tensor_name'],\n",
    "              model_info['resized_input_tensor_name'],\n",
    "          ]))\n",
    "  return graph, bottleneck_tensor, resized_input_tensor\n",
    "\n",
    "# Gather information about the model architecture we'll be using.\n",
    "architecture='mobilenet_0.50_224'\n",
    "model_info = create_model_info(architecture=architecture)\n",
    "\n",
    "# Set up the pre-trained graph.\n",
    "model_dir='tf_files/models/'\n",
    "maybe_download_and_extract(model_info['data_url'], model_dir)\n",
    "graph, bottleneck_tensor, resized_image_tensor = (create_model_graph(model_info, model_dir))\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exercise 1: Generate training, validation and test datasets\n",
    "\n",
    "All the candies images we dispose for this training are located in the Cloud Storage folder **gs://candies-ml/dataset/v1/images**. Images are further organized into subfolders by class: almondjoy, bounty, dove, mars, milkyway, snickers, threemusketeers, twix.\n",
    "\n",
    "Your first task is to separate all the candies images into 3 distinct subsets:\n",
    "* Training (70%): the dataset on which cross-entropy loss will be minimized through gradient descent during training\n",
    "* Validation (15%): the dataset on which the accuracy and the cross entropy of the model will be measured periodically during training\n",
    "* Test (15%): the dataset on which the final accuracy of the model will be calculated after training\n",
    "\n",
    "In order to achieve this you will need to fill in the method **create_image_lists** by adding the image ('base_name' variable) consistently in either the training set, validation set or test set based on a probability calculated from a hash of the image file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "  \"\"\"Builds a list of training images from the file system.\n",
    "\n",
    "  Analyzes the sub folders in the image directory, splits them into stable\n",
    "  training, testing, and validation sets, and returns a data structure\n",
    "  describing the lists of images for each label and their paths.\n",
    "\n",
    "  Args:\n",
    "    image_dir: String path to a folder containing subfolders of images.\n",
    "    testing_percentage: Integer percentage of the images to reserve for tests.\n",
    "    validation_percentage: Integer percentage of images reserved for validation.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing an entry for each label subfolder, with images split\n",
    "    into training, testing, and validation sets within each label.\n",
    "  \"\"\"\n",
    "  if not gfile.Exists(image_dir):\n",
    "    tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "    return None\n",
    "  result = collections.OrderedDict()\n",
    "  sub_dirs = gfile.ListDirectory(image_dir)\n",
    "  sub_dirs = sorted(\n",
    "    item for item in sub_dirs\n",
    "    if gfile.IsDirectory(os.path.join(image_dir, item)))\n",
    "  print(sub_dirs)\n",
    "  for dir_name in sub_dirs:\n",
    "    extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "    file_list = []\n",
    "    if dir_name == image_dir:\n",
    "      continue\n",
    "    tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n",
    "\n",
    "    for extension in extensions:\n",
    "      file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "      file_list.extend(gfile.Glob(file_glob))\n",
    "    if not file_list:\n",
    "      tf.logging.warning('No files found')\n",
    "      continue\n",
    "    if len(file_list) < 20:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "    elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder {} has more than {} images. Some images will '\n",
    "          'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "    label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "    training_images = []\n",
    "    testing_images = []\n",
    "    validation_images = []\n",
    "    for file_name in file_list:\n",
    "      base_name = os.path.basename(file_name)\n",
    "      hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "      hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "      percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_IMAGES_PER_CLASS + 1)) * (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "      \n",
    "      # Based on the percentage_hash probability add the image (base_name)\n",
    "      # in a consistent manner in either the validation set, test set or\n",
    "      # training set. \n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "    result[label_name] = {\n",
    "        'dir': dir_name,\n",
    "        'training': training_images,\n",
    "        'testing': testing_images,\n",
    "        'validation': validation_images,\n",
    "    }\n",
    "  return result\n",
    "\n",
    "image_dir='gs://candies-ml/dataset/v1/images'\n",
    "testing_percentage=15\n",
    "validation_percentage=15\n",
    "image_lists = create_image_lists(image_dir=image_dir,\n",
    "                                 testing_percentage=testing_percentage,\n",
    "                                 validation_percentage=validation_percentage)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solution\n",
    "Display the content of the box below to see the solution to the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "  \"\"\"Builds a list of training images from the file system.\n",
    "\n",
    "  Analyzes the sub folders in the image directory, splits them into stable\n",
    "  training, testing, and validation sets, and returns a data structure\n",
    "  describing the lists of images for each label and their paths.\n",
    "\n",
    "  Args:\n",
    "    image_dir: String path to a folder containing subfolders of images.\n",
    "    testing_percentage: Integer percentage of the images to reserve for tests.\n",
    "    validation_percentage: Integer percentage of images reserved for validation.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing an entry for each label subfolder, with images split\n",
    "    into training, testing, and validation sets within each label.\n",
    "  \"\"\"\n",
    "  if not gfile.Exists(image_dir):\n",
    "    tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "    return None\n",
    "  result = collections.OrderedDict()\n",
    "  sub_dirs = gfile.ListDirectory(image_dir)\n",
    "  sub_dirs = sorted(\n",
    "    item for item in sub_dirs\n",
    "    if gfile.IsDirectory(os.path.join(image_dir, item)))\n",
    "  print(sub_dirs)\n",
    "  for dir_name in sub_dirs:\n",
    "    extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "    file_list = []\n",
    "    if dir_name == image_dir:\n",
    "      continue\n",
    "    tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n",
    "\n",
    "    for extension in extensions:\n",
    "      file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "      file_list.extend(gfile.Glob(file_glob))\n",
    "    if not file_list:\n",
    "      tf.logging.warning('No files found')\n",
    "      continue\n",
    "    if len(file_list) < 20:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "    elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder {} has more than {} images. Some images will '\n",
    "          'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "    label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "    training_images = []\n",
    "    testing_images = []\n",
    "    validation_images = []\n",
    "    for file_name in file_list:\n",
    "      base_name = os.path.basename(file_name)\n",
    "      hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "      hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "      percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_IMAGES_PER_CLASS + 1)) * (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "      if percentage_hash < validation_percentage:\n",
    "        validation_images.append(base_name)\n",
    "      elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        testing_images.append(base_name)\n",
    "      else:\n",
    "        training_images.append(base_name)\n",
    "        \n",
    "    result[label_name] = {\n",
    "        'dir': dir_name,\n",
    "        'training': training_images,\n",
    "        'testing': testing_images,\n",
    "        'validation': validation_images,\n",
    "    }\n",
    "  return result\n",
    "\n",
    "image_dir='gs://candies-ml/dataset/v1/images'\n",
    "testing_percentage=15\n",
    "validation_percentage=15\n",
    "image_lists = create_image_lists(image_dir=image_dir,\n",
    "                                 testing_percentage=testing_percentage,\n",
    "                                 validation_percentage=validation_percentage)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Extract bottlenecks for all images\n",
    "You are now ready to generate the bottlenecks, or image feature vectors, for all images in your training, validation and test datasets respectively. Using the MobileNet TensorFlow graph loaded in the **graph** global variable and **model_info** variable containing information about the input images resolution expected by the MobileNet model, the code below runs a TensorFlow session on the loaded graph which does the following:\n",
    "* Converts each image to the expected resolution (224px in our case)\n",
    "* Extracts the bottleneck features by running the loaded graph on the image\n",
    "* Saves the bottleneck features in a file for each image\n",
    "<p>\n",
    "\n",
    "**This is the longest step in the training process and may take up to 10 minutes. Please be patient.**\n",
    "<p>\n",
    "Display the content of the box if you want to have a closer look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "  \"\"\"\"Returns a path to an image for a label at the given index.\n",
    "\n",
    "  Args:\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Int offset of the image we want. This will be moduloed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    category: Name string of set to pull images from - training, testing, or\n",
    "    validation.\n",
    "\n",
    "  Returns:\n",
    "    File system path string to an image that meets the requested parameters.\n",
    "\n",
    "  \"\"\"\n",
    "  if label_name not in image_lists:\n",
    "    tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "  label_lists = image_lists[label_name]\n",
    "  if category not in label_lists:\n",
    "    tf.logging.fatal('Category does not exist %s.', category)\n",
    "  category_list = label_lists[category]\n",
    "  if not category_list:\n",
    "    tf.logging.fatal('Label %s has no images in the category %s.',\n",
    "                     label_name, category)\n",
    "  mod_index = index % len(category_list)\n",
    "  base_name = category_list[mod_index]\n",
    "  sub_dir = label_lists['dir']\n",
    "  full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "  return full_path\n",
    "\n",
    "\n",
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir,\n",
    "                        category, architecture):\n",
    "  \"\"\"\"Returns a path to a bottleneck file for a label at the given index.\n",
    "\n",
    "  Args:\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Integer offset of the image we want. This will be moduloed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    category: Name string of set to pull images from - training, testing, or\n",
    "    validation.\n",
    "    architecture: The name of the model architecture.\n",
    "\n",
    "  Returns:\n",
    "    File system path string to an image that meets the requested parameters.\n",
    "  \"\"\"\n",
    "  return get_image_path(image_lists, label_name, index, bottleneck_dir,\n",
    "                        category) + '_' + architecture + '.txt'\n",
    "\n",
    "\n",
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n",
    "                            decoded_image_tensor, resized_input_tensor,\n",
    "                            bottleneck_tensor):\n",
    "  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\n",
    "\n",
    "  Args:\n",
    "    sess: Current active TensorFlow Session.\n",
    "    image_data: String of raw JPEG data.\n",
    "    image_data_tensor: Input data layer in the graph.\n",
    "    decoded_image_tensor: Output of initial image resizing and  preprocessing.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: Layer before the final softmax.\n",
    "\n",
    "  Returns:\n",
    "    Numpy array of bottleneck values.\n",
    "  \"\"\"\n",
    "  # First decode the JPEG image, resize it, and rescale the pixel values.\n",
    "  resized_input_values = sess.run(decoded_image_tensor,\n",
    "                                  {image_data_tensor: image_data})\n",
    "  # Then run it through the recognition network.\n",
    "  bottleneck_values = sess.run(bottleneck_tensor,\n",
    "                               {resized_input_tensor: resized_input_values})\n",
    "  bottleneck_values = np.squeeze(bottleneck_values)\n",
    "  return bottleneck_values\n",
    "\n",
    "\n",
    "bottleneck_path_2_bottleneck_values = {}\n",
    "\n",
    "\n",
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor):\n",
    "  \"\"\"Create a single bottleneck file.\"\"\"\n",
    "  tf.logging.info('Creating bottleneck at ' + bottleneck_path)\n",
    "  image_path = get_image_path(image_lists, label_name, index,\n",
    "                              image_dir, category)\n",
    "  if not gfile.Exists(image_path):\n",
    "    tf.logging.fatal('File does not exist %s', image_path)\n",
    "  image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "  try:\n",
    "    bottleneck_values = run_bottleneck_on_image(\n",
    "        sess, image_data, jpeg_data_tensor, decoded_image_tensor,\n",
    "        resized_input_tensor, bottleneck_tensor)\n",
    "  except Exception as e:\n",
    "    raise RuntimeError('Error during processing file %s (%s)' % (image_path,\n",
    "                                                                 str(e)))\n",
    "  bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "  with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "    bottleneck_file.write(bottleneck_string)\n",
    "\n",
    "\n",
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\n",
    "                             category, bottleneck_dir, jpeg_data_tensor,\n",
    "                             decoded_image_tensor, resized_input_tensor,\n",
    "                             bottleneck_tensor, architecture):\n",
    "  \"\"\"Retrieves or calculates bottleneck values for an image.\n",
    "\n",
    "  If a cached version of the bottleneck data exists on-disk, return that,\n",
    "  otherwise calculate the data and save it to disk for future use.\n",
    "\n",
    "  Args:\n",
    "    sess: The current active TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Integer offset of the image we want. This will be modulo-ed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    image_dir: Root folder string  of the subfolders containing the training\n",
    "    images.\n",
    "    category: Name string of which  set to pull images from - training, testing,\n",
    "    or validation.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    jpeg_data_tensor: The tensor to feed loaded jpeg data into.\n",
    "    decoded_image_tensor: The output of decoding and resizing the image.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The output tensor for the bottleneck values.\n",
    "    architecture: The name of the model architecture.\n",
    "\n",
    "  Returns:\n",
    "    Numpy array of values produced by the bottleneck layer for the image.\n",
    "  \"\"\"\n",
    "  label_lists = image_lists[label_name]\n",
    "  sub_dir = label_lists['dir']\n",
    "  sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "  ensure_dir_exists(sub_dir_path)\n",
    "  bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n",
    "                                        bottleneck_dir, category, architecture)\n",
    "  if not os.path.exists(bottleneck_path):\n",
    "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor)\n",
    "  with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "    bottleneck_string = bottleneck_file.read()\n",
    "  did_hit_error = False\n",
    "  try:\n",
    "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "  except ValueError:\n",
    "    tf.logging.warning('Invalid float found, recreating bottleneck')\n",
    "    did_hit_error = True\n",
    "  if did_hit_error:\n",
    "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor)\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "      bottleneck_string = bottleneck_file.read()\n",
    "    # Allow exceptions to propagate here, since they shouldn't happen after a\n",
    "    # fresh creation\n",
    "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "  return bottleneck_values, bottleneck_string\n",
    "\n",
    "\n",
    "def add_jpeg_decoding(input_width, input_height, input_depth, input_mean,\n",
    "                      input_std):\n",
    "  \"\"\"Adds operations that perform JPEG decoding and resizing to the graph..\n",
    "\n",
    "  Args:\n",
    "    input_width: Desired width of the image fed into the recognizer graph.\n",
    "    input_height: Desired width of the image fed into the recognizer graph.\n",
    "    input_depth: Desired channels of the image fed into the recognizer graph.\n",
    "    input_mean: Pixel value that should be zero in the image for the graph.\n",
    "    input_std: How much to divide the pixel values by before recognition.\n",
    "\n",
    "  Returns:\n",
    "    Tensors for the node to feed JPEG data into, and the output of the\n",
    "      preprocessing steps.\n",
    "  \"\"\"\n",
    "  jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\n",
    "  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n",
    "  decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "  resize_shape = tf.stack([input_height, input_width])\n",
    "  resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "  resized_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                           resize_shape_as_int)\n",
    "  offset_image = tf.subtract(resized_image, input_mean)\n",
    "  mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "  return jpeg_data, mul_image\n",
    "\n",
    "\n",
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n",
    "                      jpeg_data_tensor, decoded_image_tensor,\n",
    "                      resized_input_tensor, bottleneck_tensor, architecture):\n",
    "  \"\"\"Ensures all the training, testing, and validation bottlenecks are cached.\n",
    "\n",
    "  Because we're likely to read the same image multiple times it can speed\n",
    "  things up a lot if we calculate the bottleneck layer values once for each\n",
    "  image during preprocessing, and then just read those cached values\n",
    "  repeatedly during training. Here we go through all the images we've found,\n",
    "  calculate those values, and save them off.\n",
    "\n",
    "  Args:\n",
    "    sess: The current active TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    jpeg_data_tensor: Input tensor for jpeg data from file.\n",
    "    decoded_image_tensor: The output of decoding and resizing the image.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The penultimate output layer of the graph.\n",
    "    architecture: The name of the model architecture.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  how_many_bottlenecks = 0\n",
    "  ensure_dir_exists(bottleneck_dir)\n",
    "  bottleneck_gcs_dir = os.path.join(bucket, 'bottlenecks')\n",
    "  for category in ['training', 'testing', 'validation']:\n",
    "    bottlenecks = []\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "      category_list = label_lists[category]\n",
    "      for index, unused_base_name in enumerate(category_list):\n",
    "        _, bottleneck_string = get_or_create_bottleneck(\n",
    "            sess, image_lists, label_name, index, image_dir, category,\n",
    "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "            resized_input_tensor, bottleneck_tensor, architecture)\n",
    "        bottlenecks.append('%s,%s\\n' % (bottleneck_string, label_name.strip()))\n",
    "\n",
    "        how_many_bottlenecks += 1\n",
    "        if how_many_bottlenecks % 100 == 0:\n",
    "          tf.logging.info(str(how_many_bottlenecks) + ' bottleneck files created.')\n",
    "    \n",
    "    # Saving bottlenecks on GCS by category for Cloud ML Engine training\n",
    "    bottleneck_gcs_path = os.path.join(bottleneck_gcs_dir, '%s.csv' % category)\n",
    "    tf.logging.info('Writing %s bottlenecks on GCS to %s.' % (category, bottleneck_gcs_path))\n",
    "    with gfile.FastGFile(bottleneck_gcs_path, 'w') as bottleneck_gcs_file:\n",
    "      for bottleneck_string in bottlenecks:\n",
    "        bottleneck_gcs_file.write(bottleneck_string)\n",
    "      bottleneck_gcs_file.close()\n",
    "\n",
    "\n",
    "bottleneck_dir='/tmp/bottleneck'\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  # Set up the image decoding sub-graph.\n",
    "  jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\n",
    "      model_info['input_width'], model_info['input_height'],\n",
    "      model_info['input_depth'], model_info['input_mean'],\n",
    "      model_info['input_std'])\n",
    "\n",
    "  # We'll make sure we've calculated the 'bottleneck' image summaries and\n",
    "  # cached them on disk.\n",
    "  cache_bottlenecks(sess, image_lists, image_dir,\n",
    "                    bottleneck_dir, jpeg_data_tensor,\n",
    "                    decoded_image_tensor, resized_image_tensor,\n",
    "                    bottleneck_tensor, architecture)\n",
    "  \n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Code the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 2: Retrain the last layer of the model\n",
    "After the bottlenecks have been extracted for each image of the dataset, retraining the last layer of the model implies the following:\n",
    "* Applying [softmax](https://en.wikipedia.org/wiki/Softmax_function) to calculate the predictions of the last leayer for each one of the new classes\n",
    "* Calculating the [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) loss with respect to the ground truth (the actual candies labels)\n",
    "* Adjusting the weights and biases of the last layer through gradient descent in order to minimize the cross entropy loss\n",
    "\n",
    "<p>\n",
    "Your task in this exercise is to fully code the training of the last layer by following the indications in the code below.\n",
    "<p>\n",
    "*Please remember that TensorFlow has a deferred execution model. Therefore, the code you will write in this section will be executed in the **Run the training** section below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "\n",
    "\n",
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor,\n",
    "                           bottleneck_tensor_size, learning_rate):\n",
    "  \"\"\"Adds a new softmax and fully-connected layer for training.\n",
    "\n",
    "  We need to retrain the top layer to identify our new classes, so this function\n",
    "  adds the right operations to the graph, along with some variables to hold the\n",
    "  weights, and then sets up all the gradients for the backward pass.\n",
    "\n",
    "  The set up for the softmax and fully-connected layers is based on:\n",
    "  https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\n",
    "\n",
    "  Args:\n",
    "    class_count: Integer of how many categories of things we're trying to\n",
    "    recognize.\n",
    "    final_tensor_name: Name string for the new final node that produces results.\n",
    "    bottleneck_tensor: The output of the main CNN graph.\n",
    "    bottleneck_tensor_size: How many entries in the bottleneck vector.\n",
    "\n",
    "  Returns:\n",
    "    The tensors for the training and cross entropy results, and tensors for the\n",
    "    bottleneck input and ground truth input.\n",
    "  \"\"\"\n",
    "  with tf.name_scope('input'):\n",
    "    bottleneck_input = tf.placeholder_with_default(\n",
    "        bottleneck_tensor,\n",
    "        shape=[None, bottleneck_tensor_size],\n",
    "        name='BottleneckInputPlaceholder')\n",
    "\n",
    "    ground_truth_input = tf.placeholder(tf.float32,\n",
    "                                        [None, class_count],\n",
    "                                        name='GroundTruthInput')\n",
    "\n",
    "  # Organizing the following ops as `final_training_ops` so they're easier\n",
    "  # to see in TensorBoard\n",
    "  layer_name = 'final_training_ops'\n",
    "  with tf.name_scope(layer_name):\n",
    "    \n",
    "    with tf.name_scope('weights'):\n",
    "      \n",
    "      # Create the 'layer_weights' tensor variable with the following characteristics:\n",
    "      # - size: entries_in_the_bottleneck_vector x number_of_classes\n",
    "      # - initial values: truncated normal distribution of 0.001 standard deviation\n",
    "      # - name: \"final_weights\"\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "      variable_summaries(layer_weights)\n",
    "      \n",
    "    with tf.name_scope('biases'):\n",
    "      \n",
    "      # Create the 'layer_biases' tensor variable with the following characteristics:\n",
    "      # - size: number of classes\n",
    "      # - initial values: 0\n",
    "      # - name: \"final_biases\"\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "      variable_summaries(layer_biases)\n",
    "      \n",
    "    with tf.name_scope('logits'):\n",
    "      \n",
    "      # Create the 'logits' operation for calculating the last layer logits:\n",
    "      # logits = input * weights + biases\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "      tf.summary.histogram('pre_activations', logits)\n",
    "  \n",
    "  # Create the 'final_tensor' representing the predictions of the last\n",
    "  # layer by applying softmax on the logits previously calculated. Name\n",
    "  # it with the value of the parameter 'final_tensor_name'. \n",
    "  # <YOUR CODE HERE>\n",
    "  raise NotImplementedError()\n",
    "  \n",
    "  tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "  with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    # Calculate the cross entropy loss as the difference between\n",
    "    # the predicted labels and the ground truth.\n",
    "    # Hint: tf.nn.softmax_cross_entropy_with_logits()\n",
    "    # <YOUR CODE HERE>\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    with tf.name_scope('total'):\n",
    "\n",
    "      # Average the cross entropy over all the examples in the\n",
    "      # current batch.\n",
    "      # Hint: tf.reduce_mean()\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "  tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "  with tf.name_scope('train'):\n",
    "\n",
    "    # Create a gradient descent optimizer with the given learning\n",
    "    # rate. Create the 'training_step' operation that minimises \n",
    "    # the mean cross entropy with gradient descent.\n",
    "    # <YOUR CODE HERE>\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n",
    "          final_tensor)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solution\n",
    "Display the content of the box below to see the solution to the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "\n",
    "\n",
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor,\n",
    "                           bottleneck_tensor_size, learning_rate):\n",
    "  \"\"\"Adds a new softmax and fully-connected layer for training.\n",
    "\n",
    "  We need to retrain the top layer to identify our new classes, so this function\n",
    "  adds the right operations to the graph, along with some variables to hold the\n",
    "  weights, and then sets up all the gradients for the backward pass.\n",
    "\n",
    "  The set up for the softmax and fully-connected layers is based on:\n",
    "  https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\n",
    "\n",
    "  Args:\n",
    "    class_count: Integer of how many categories of things we're trying to\n",
    "    recognize.\n",
    "    final_tensor_name: Name string for the new final node that produces results.\n",
    "    bottleneck_tensor: The output of the main CNN graph.\n",
    "    bottleneck_tensor_size: How many entries in the bottleneck vector.\n",
    "\n",
    "  Returns:\n",
    "    The tensors for the training and cross entropy results, and tensors for the\n",
    "    bottleneck input and ground truth input.\n",
    "  \"\"\"\n",
    "  with tf.name_scope('input'):\n",
    "    bottleneck_input = tf.placeholder_with_default(\n",
    "        bottleneck_tensor,\n",
    "        shape=[None, bottleneck_tensor_size],\n",
    "        name='BottleneckInputPlaceholder')\n",
    "\n",
    "    ground_truth_input = tf.placeholder(tf.float32,\n",
    "                                        [None, class_count],\n",
    "                                        name='GroundTruthInput')\n",
    "\n",
    "  # Organizing the following ops as `final_training_ops` so they're easier\n",
    "  # to see in TensorBoard\n",
    "  layer_name = 'final_training_ops'\n",
    "  with tf.name_scope(layer_name):\n",
    "    with tf.name_scope('weights'):\n",
    "      initial_value = tf.truncated_normal([bottleneck_tensor_size, class_count], stddev=0.001)\n",
    "      layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "      variable_summaries(layer_weights)\n",
    "    with tf.name_scope('biases'):\n",
    "      layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "      variable_summaries(layer_biases)\n",
    "    with tf.name_scope('logits'):\n",
    "      logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "      tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "  final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "  tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "  with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=ground_truth_input, logits=logits)\n",
    "    with tf.name_scope('total'):\n",
    "      cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "  tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "  with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_step = optimizer.minimize(cross_entropy_mean)\n",
    "\n",
    "  return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n",
    "          final_tensor)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 3: Calculate the accuracy\n",
    "**Accuracy** is one of the metrics of success of our model. It is defined as the percentage of predictions generated by our model that are correct.\n",
    "<p>\n",
    "Your task in this exercise is to code the calculation of the accuracy on a given dataset following the indications in the code below.\n",
    "\n",
    "*Please remember that TensorFlow has a deferred execution model. Therefore, the code you will write in this section will be executed in the **Run the training** section below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\n",
    "\n",
    "  Args:\n",
    "    result_tensor: The new final node that produces results.\n",
    "    ground_truth_tensor: The node we feed ground truth data\n",
    "    into.\n",
    "\n",
    "  Returns:\n",
    "    Tuple of (evaluation step, prediction).\n",
    "  \"\"\"\n",
    "  with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "      \n",
    "      # Create a 'prediction' tensor containing the predicted class. Remember\n",
    "      # that the 'result_tensor' contains a probability distribution of predictions\n",
    "      # for all classes for all examples in the batch and the class with the\n",
    "      # highest probability is considered to be the predicted one.\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "            \n",
    "      # Calculate all the correct predictions by comparing the 'prediction' tnesor\n",
    "      # with the ground_truth_tensor.\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "    with tf.name_scope('accuracy'):\n",
    "      \n",
    "      # Create an 'evaluation_step' averaging the correct prediction over all\n",
    "      # examples in the batch.\n",
    "      # <YOUR CODE HERE>\n",
    "      raise NotImplementedError()\n",
    "      \n",
    "  tf.summary.scalar('accuracy', evaluation_step)\n",
    "  return evaluation_step, prediction\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solution\n",
    "Display the content of the box below to see the solution to the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\n",
    "\n",
    "  Args:\n",
    "    result_tensor: The new final node that produces results.\n",
    "    ground_truth_tensor: The node we feed ground truth data\n",
    "    into.\n",
    "\n",
    "  Returns:\n",
    "    Tuple of (evaluation step, prediction).\n",
    "  \"\"\"\n",
    "  with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "      prediction = tf.argmax(result_tensor, 1)\n",
    "      correct_prediction = tf.equal(\n",
    "          prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "      evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.summary.scalar('accuracy', evaluation_step)\n",
    "  return evaluation_step, prediction\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save the graph to a file\n",
    "The last step of the training is to save the TensorFlow graph in a file for serving or deployment on mobile devices. Please run the code in the box below to create the method that will save the TensorFlow graph in a file at the end of the training.\n",
    "<p>\n",
    "Display the content of the box if you want to have a closer look at the code.\n",
    "<p>\n",
    "*Please remember that TensorFlow has a deferred execution model. Therefore, the code you will write in this section will be executed in the **Run the training** section below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_graph_to_file(sess, graph, graph_file_name, final_tensor_name):\n",
    "  output_graph_def = graph_util.convert_variables_to_constants(\n",
    "      sess, graph.as_graph_def(), [final_tensor_name])\n",
    "  with gfile.FastGFile(graph_file_name, 'wb') as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "  return\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run TensorBoard\n",
    "Before launching the training run [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), the learning visualization tool for TensorFlow. TensorBoard allows you to visualize precise metrics of your training, in our case **accuracy** and **cross entropy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "tb_id = TensorBoard.start('tf_files/training_summaries/mobilenet_0.50_224')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run the training\n",
    "The training of the model will run for 1000 steps. At each step the weights and biases of the last layer will be adjusted to decrease the cross entropy loss on the training set.\n",
    "<p>\n",
    "Every 10 steps the accuracy and the cross entropy loss will be calculated on the validation set.\n",
    "<p>\n",
    "At the end of the training the final accuracy will be calculated on the test set and all misclassified images will be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category,\n",
    "                                  bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                                  decoded_image_tensor, resized_input_tensor,\n",
    "                                  bottleneck_tensor, architecture):\n",
    "  \"\"\"Retrieves bottleneck values for cached images directly from disk. It\n",
    "  picks a random set of images from the specified category.\n",
    "\n",
    "  Args:\n",
    "    sess: Current TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    how_many: If positive, a random sample of this size will be chosen.\n",
    "    If negative, all bottlenecks will be retrieved.\n",
    "    category: Name string of which set to pull from - training, testing, or\n",
    "    validation.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    jpeg_data_tensor: The layer to feed jpeg image data into.\n",
    "    decoded_image_tensor: The output of decoding and resizing the image.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The bottleneck output layer of the CNN graph.\n",
    "    architecture: The name of the model architecture.\n",
    "\n",
    "  Returns:\n",
    "    List of bottleneck arrays, their corresponding ground truths, and the\n",
    "    relevant filenames.\n",
    "  \"\"\"\n",
    "  class_count = len(image_lists.keys())\n",
    "  bottlenecks = []\n",
    "  ground_truths = []\n",
    "  filenames = []\n",
    "  if how_many >= 0:\n",
    "    # Retrieve a random sample of bottlenecks.\n",
    "    for unused_i in range(how_many):\n",
    "      label_index = random.randrange(class_count)\n",
    "      label_name = list(image_lists.keys())[label_index]\n",
    "      image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "      image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                  image_dir, category)\n",
    "      bottleneck, _ = get_or_create_bottleneck(\n",
    "          sess, image_lists, label_name, image_index, image_dir, category,\n",
    "          bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "          resized_input_tensor, bottleneck_tensor, architecture)\n",
    "      ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "      ground_truth[label_index] = 1.0\n",
    "      bottlenecks.append(bottleneck)\n",
    "      ground_truths.append(ground_truth)\n",
    "      filenames.append(image_name)\n",
    "  else:\n",
    "    # Retrieve all bottlenecks.\n",
    "    for label_index, label_name in enumerate(image_lists.keys()):\n",
    "      for image_index, image_name in enumerate(\n",
    "          image_lists[label_name][category]):\n",
    "        image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                    image_dir, category)\n",
    "        bottleneck, _ = get_or_create_bottleneck(\n",
    "            sess, image_lists, label_name, image_index, image_dir, category,\n",
    "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "            resized_input_tensor, bottleneck_tensor, architecture)\n",
    "        ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "        ground_truth[label_index] = 1.0\n",
    "        bottlenecks.append(bottleneck)\n",
    "        ground_truths.append(ground_truth)\n",
    "        filenames.append(image_name)\n",
    "  return bottlenecks, ground_truths, filenames\n",
    "\n",
    "\n",
    "def retrain(architecture='mobilenet_0.50_224',\n",
    "            image_dir='gs://candies-ml/dataset/v2/images',\n",
    "            output_graph='gs://candies-ml/model/test/retrained_graph.pb',\n",
    "            output_labels='gs://candies-ml/model/test/retrained_labels.txt',\n",
    "            final_tensor_name='final_result',\n",
    "            how_many_training_steps=1000,\n",
    "            eval_step_interval=10,\n",
    "            learning_rate=0.01,\n",
    "            train_batch_size=100,\n",
    "            test_batch_size=-1,\n",
    "            validation_batch_size=100,\n",
    "            intermediate_store_frequency=0,\n",
    "            intermediate_output_graphs_dir='/tmp/intermediate_graph/',\n",
    "            bottleneck_dir='/tmp/bottleneck',\n",
    "            summaries_dir='tf_files/training_summaries/mobilenet_0.50_224',         \n",
    "            print_misclassified_test_images=True):\n",
    "\n",
    "  # Look at the folder structure, and create lists of all the images.\n",
    "  class_count = len(image_lists.keys())\n",
    "\n",
    "  with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    # Add the new layer that we'll be training.\n",
    "    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n",
    "     final_tensor) = add_final_training_ops(\n",
    "         len(image_lists.keys()), final_tensor_name, bottleneck_tensor,\n",
    "         model_info['bottleneck_tensor_size'], learning_rate)\n",
    "\n",
    "    # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "    evaluation_step, prediction = add_evaluation_step(\n",
    "        final_tensor, ground_truth_input)\n",
    "\n",
    "    # Merge all the summaries and write them out to the summaries_dir\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train', sess.graph)\n",
    "    validation_writer = tf.summary.FileWriter(summaries_dir + '/validation')\n",
    "\n",
    "    # Set up all our weights to their initial default values.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Run the training for as many cycles as requested on the command line.\n",
    "    for i in range(how_many_training_steps):\n",
    "      # Get a batch of input bottleneck values from the cache stored on disk.\n",
    "      (train_bottlenecks,\n",
    "       train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "           sess, image_lists, train_batch_size, 'training',\n",
    "           bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "           decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "           architecture)\n",
    "      \n",
    "      # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "      # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "      train_summary, _ = sess.run(\n",
    "          [merged, train_step],\n",
    "          feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                     ground_truth_input: train_ground_truth})\n",
    "      train_writer.add_summary(train_summary, i)\n",
    "\n",
    "      # Every so often, print out how well the graph is training.\n",
    "      is_last_step = (i + 1 == how_many_training_steps)\n",
    "      if (i % eval_step_interval) == 0 or is_last_step:\n",
    "        train_accuracy, cross_entropy_value = sess.run(\n",
    "            [evaluation_step, cross_entropy],\n",
    "            feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                       ground_truth_input: train_ground_truth})\n",
    "        tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n",
    "                        (datetime.now(), i, train_accuracy * 100))\n",
    "        tf.logging.info('%s: Step %d: Cross entropy = %f' %\n",
    "                        (datetime.now(), i, cross_entropy_value))\n",
    "        validation_bottlenecks, validation_ground_truth, _ = (\n",
    "            get_random_cached_bottlenecks(\n",
    "                sess, image_lists, validation_batch_size, 'validation',\n",
    "                bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                architecture))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "        validation_summary, validation_accuracy = sess.run(\n",
    "            [merged, evaluation_step],\n",
    "            feed_dict={bottleneck_input: validation_bottlenecks,\n",
    "                       ground_truth_input: validation_ground_truth})\n",
    "        validation_writer.add_summary(validation_summary, i)\n",
    "        tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                        (datetime.now(), i, validation_accuracy * 100,\n",
    "                         len(validation_bottlenecks)))\n",
    "\n",
    "      # Store intermediate results\n",
    "      intermediate_frequency = intermediate_store_frequency\n",
    "\n",
    "      if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\n",
    "          and i > 0):\n",
    "        intermediate_file_name = (intermediate_output_graphs_dir +\n",
    "                                  'intermediate_' + str(i) + '.pb')\n",
    "        tf.logging.info('Save intermediate result to : ' +\n",
    "                        intermediate_file_name)\n",
    "        save_graph_to_file(sess, graph, intermediate_file_name, final_tensor_name)\n",
    "\n",
    "    # We've completed all our training, so run a final test evaluation on\n",
    "    # some new images we haven't used before.\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(\n",
    "            sess, image_lists, test_batch_size, 'testing',\n",
    "            bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "            architecture))\n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction],\n",
    "        feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                   ground_truth_input: test_ground_truth})\n",
    "    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                    (test_accuracy * 100, len(test_bottlenecks)))\n",
    "\n",
    "    if print_misclassified_test_images:\n",
    "      tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n",
    "      for i, test_filename in enumerate(test_filenames):\n",
    "        if predictions[i] != test_ground_truth[i].argmax():\n",
    "          tf.logging.info('%70s  %s' %\n",
    "                          (test_filename,\n",
    "                           list(image_lists.keys())[predictions[i]]))\n",
    "\n",
    "    # Write out the trained graph and labels with the weights stored as\n",
    "    # constants.\n",
    "    save_graph_to_file(sess, graph, output_graph, final_tensor_name)\n",
    "    with gfile.FastGFile(output_labels, 'w') as f:\n",
    "      f.write('\\n'.join(image_lists.keys()) + '\\n')      \n",
    "\n",
    "output_graph_path='%s/retrained_graph.pb' % bucket\n",
    "output_labels_path='%s/retrained_labels.txt' % bucket\n",
    "retrain(architecture=architecture,\n",
    "        image_dir=image_dir,\n",
    "        output_graph=output_graph_path,\n",
    "        output_labels=output_labels_path,\n",
    "        summaries_dir=summaries_dir,\n",
    "        intermediate_output_graphs_dir=intermediate_output_graphs_dir,\n",
    "        intermediate_store_frequency=intermediate_store_frequency,\n",
    "        bottleneck_dir=bottleneck_dir)\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exercise 4: Evaluate the model\n",
    "As an exercise to understand the behavior of the model please try to answer the following questions:\n",
    "* How do the accuracy and cross entropy behave on the training set? Could you explain why?\n",
    "* How do the accuracy and the cross entropy behave on the validation set? Could you explain why?\n",
    "* What is the final accuracy of the model on the test set?\n",
    "* What images were misclassified? Could you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the model on Cloud ML Engine\n",
    "<p>\n",
    "### Preliminaries\n",
    "In this section you will retrain the MobileNet model on Cloud ML Engine.\n",
    "<p>\n",
    "The main code that you will be running on Cloud ML Engine is the same as the one you wrote in this notebook. However, to be able to run it on Cloud ML Engine, the code is packaged in the [**trainer**](https://github.com/dan-anghel/datalab-ml/tree/master/trainer) module containing 2 Python source files:\n",
    "* [model.py](https://github.com/dan-anghel/datalab-ml/blob/master/trainer/model.py) containing the TensorFlow model training code\n",
    "* [task.py](https://github.com/dan-anghel/datalab-ml/blob/master/trainer/task.py) containing the TensorFlow code for [distributed training](https://www.tensorflow.org/deploy/distributed) \n",
    "\n",
    "To run the training on Cloud ML Engine you will run the [gcloud ml-engine](https://cloud.google.com/sdk/gcloud/reference/ml-engine/) command and pass it, among others, the following generic parameters:\n",
    "* The name of the job\n",
    "* The [runtime version](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
    "* The name of the Python module to run\n",
    "* The job directory on Cloud Storage where TensorFlow checkpoints will be saved\n",
    "\n",
    "You will also pass to the training job some specific parameters, like the Cloud Storage path of the training and validation data and the number of steps. Please note that the input data set for this training are the bottlenecks previously generated from the images which are store on Cloud Storage:\n",
    "* Training data: **gs://[GCP_PROJECT_ID]-image-classifier/bottlenecks/training.csv**\n",
    "* Validation data: **gs://[GCP_PROJECT_ID]-image-classifier/bottlenecks/validation.csv**\n",
    "\n",
    "<p>\n",
    "### Exercise 5: Run the training job on Cloud ML Engine\n",
    "Run the code in the box below and attempt to accomplish the following tasks:\n",
    "* Once the job has been launched, find in Cloud Console under ML Engine\n",
    "* In the Cloud Console try to visualize the logs of the ML Engine job\n",
    "* In the logs find the final accuracy on the validation data at the end of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "curr_date = '{:%Y%m%d%H%M}'.format(datetime.datetime.today())\n",
    "train_file = 'gs://[GCP_PROJECT_ID]-image-classifier/bottlenecks/training.csv'\n",
    "eval_file = 'gs://[GCP_PROJECT_ID]-image-classifier/bottlenecks/validation.csv'\n",
    "train_steps = 1000\n",
    "eval_steps = 100\n",
    "job_name = 'retrain_mobilenets_candies_%s' % curr_date\n",
    "job_dir = '%s/cloudml-training/%s' % (bucket, job_name)\n",
    "\n",
    "gcloud_template_command = \"\"\"ml-engine jobs submit training %s \\\n",
    "  --stream-logs \\\n",
    "  --runtime-version 1.8 \\\n",
    "  --job-dir %s \\\n",
    "  --module-name trainer.task \\\n",
    "  --package-path trainer/ \\\n",
    "  --region us-central1 \\\n",
    "  -- \\\n",
    "  --train-files %s \\\n",
    "  --eval-files %s \\\n",
    "  --train-steps %d \\\n",
    "  --eval-steps %d\n",
    "\"\"\"\n",
    "gcloud_command = gcloud_template_command % (job_name, job_dir, train_file, eval_file,\n",
    "                                            train_steps, eval_steps)\n",
    "print 'Submitting the Cloud ML Engine job with the command: gcloud %s' % gcloud_command\n",
    "\n",
    "!gcloud $gcloud_command\n",
    "\n",
    "print 'Execution complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cleanup\n",
    "Run the code in the box below to terminate the running Tensorboad instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TensorBoard.stop(tb_id)\n",
    "print 'Execution complete'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
