{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature extraction\n",
    "<p> \n",
    "## Overview\n",
    "This notebook demonstrates the image pre-processing necessary in transfer learning, discussed in the [How to Retrain an Image Classifier for New Categories](https://www.tensorflow.org/tutorials/image_retraining) tutorial. Transfer learning consists of using a pre-trained model, Inception V3, to create a new image classifier based on new images and custom classes. The pre-processing part covered in this notebook executes in two steps:\n",
    "*   Convert images to JPEG format\n",
    "*   Extract features from the images by running them through the Inception V3 model\n",
    "\n",
    "The main advantage of transfer learning is a cosiderable reduction in costs and training time compared to traning the classifier from scratch.\n",
    "\n",
    "This notebook does preprocessing using [Cloud Dataflow](https://cloud.google.com/dataflow/) for image and text manipulation and [TensorFlow](https://www.tensorflow.org/) for feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare imports\n",
    "Execute the code below to import all necessary Python module and initialize global variables that will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import apache_beam as beam\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.io import tfrecordio\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "project_id = datalab_project_id()\n",
    "bucket = 'gs://candies-{}-dantest'.format(project_id)\n",
    "preprocess_dir = '{}/candies_preprocessed_cloud'.format(bucket)\n",
    "model_dir = '{}/candies_model_cloud'.format(bucket)\n",
    "staging_dir = '{}/staging'.format(bucket)\n",
    "!gsutil mb $bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training data\n",
    "We will train our classifier to recognize images of candies. Let's have a look at a few samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and prepare the training data\n",
    "Code the pipeline transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 1 - Load images and labels from CSV\n",
    "TODO : Write the exercise description. Extract the list of labels and of labeled images from the CSV configuration file on GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LoadImagesAndLabels(beam.PTransform):\n",
    "  \"\"\"Load labels and labeled images from GCS.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, train_dataset):\n",
    "    super(LoadImagesAndLabels, self).__init__('LoadImagesAndLabels')\n",
    "    self._train_dataset = train_dataset\n",
    "\n",
    "  def expand(self, begin):\n",
    "    \"\"\"TODO : write the description of the function\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    # TODO : write what needs to be done in the exercise\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solution\n",
    "To see the solution please display the code in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "class LoadImagesAndLabels(beam.PTransform):\n",
    "  \"\"\"Load labels and labeled images from GCS.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, train_dataset):\n",
    "    super(LoadImagesAndLabels, self).__init__('LoadImagesAndLabels')\n",
    "    self._train_dataset = train_dataset\n",
    "\n",
    "  def expand(self, begin):\n",
    "    import csv\n",
    "    images = (begin |\n",
    "              'ReadCSVFile' >> ReadFromText(self._train_dataset, strip_trailing_newlines=True) |\n",
    "              'DictFromCSV' >> beam.Map(lambda line: csv.DictReader([line], fieldnames=['image_url', 'label']).next()))  \n",
    "    labels = (images |\n",
    "              'ExtractLabels' >> beam.Map(lambda x: str(x['label'])) |\n",
    "              'CombineLabels' >> beam.transforms.combiners.Count.PerElement() |\n",
    "              'KeepLabelName' >> beam.Map(lambda label_count: label_count[0]))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 2 - Label images with label ids\n",
    "TODO : Write the exercise description. Extracts (uri, label_ids) tuples from CSV rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LabelImagesWithIdsDoFn(beam.DoFn):\n",
    "  \"\"\"Extracts (uri, label_ids) tuples from CSV rows.\n",
    "  \"\"\"\n",
    "\n",
    "  def start_bundle(self, context=None):\n",
    "    self.label_to_id_map = {}\n",
    "\n",
    "  def process(self, element, all_labels):\n",
    "    all_labels = list(all_labels)\n",
    "    # TODO : write what needs to be done in the exercise\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solution\n",
    "To see the solution please display the code in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LabelImagesWithIdsDoFn(beam.DoFn):\n",
    "  \"\"\"Extracts (uri, label_ids) tuples from CSV rows.\n",
    "  \"\"\"\n",
    "\n",
    "  def start_bundle(self, context=None):\n",
    "    self.label_to_id_map = {}\n",
    "\n",
    "  def process(self, element, all_labels):\n",
    "    all_labels = list(all_labels)\n",
    "    # DataFlow cannot garuantee the order of the labels when materializing it.\n",
    "    # The labels materialized and consumed by training may not be in the same order\n",
    "    # as the one used in preprocessing. So we need to sort it in both preprocessing\n",
    "    # and training so the order matches.\n",
    "    all_labels.sort()\n",
    "    if not self.label_to_id_map:\n",
    "      for i, label in enumerate(all_labels):\n",
    "        label = label.strip()\n",
    "        if label:\n",
    "          self.label_to_id_map[label] = i\n",
    "\n",
    "    # Row format is:\n",
    "    # image_uri,label_id\n",
    "    if not element:\n",
    "      return\n",
    "\n",
    "    uri = element['image_url']\n",
    "    label_id = self.label_to_id_map[element['label'].strip()]\n",
    "    yield uri, label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data preparation transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrepareTrainingData(beam.PTransform):\n",
    "  \"\"\"Load labels and labeled images from GCS.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, train_dataset):\n",
    "    super(PrepareTrainingData, self).__init__('PrepareTrainingData')\n",
    "    self._train_dataset = train_dataset\n",
    "\n",
    "  def expand(self, begin):\n",
    "    images, labels = begin | 'LoadImagesAndLabels' >> LoadImagesAndLabels(self._train_dataset)\n",
    "    labeled_images = images | 'LabelImagesWithIds' >> beam.ParDo(LabelImagesWithIdsDoFn(), beam.pvalue.AsIter(labels))\n",
    "    return labeled_images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Extract features from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert images to JPEG format\n",
    "Read files from GCS and convert images to JPEG format. We do this even for JPEG images to remove variations such as different number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ConvertImagesToJpegDoFn(beam.DoFn):\n",
    "\n",
    "  def process(self, element):\n",
    "    \n",
    "    import cStringIO\n",
    "    from PIL import Image\n",
    "    from tensorflow.python.lib.io import file_io as tf_file_io\n",
    "\n",
    "    uri, label_id = element\n",
    "    try:\n",
    "      with tf_file_io.FileIO(uri, 'r') as f:\n",
    "        img = Image.open(f).convert('RGB')\n",
    "    # A variety of different calling libraries throw different exceptions here.\n",
    "    # They all correspond to an unreadable file so we treat them equivalently.\n",
    "    # pylint: disable broad-except\n",
    "    except Exception as e:\n",
    "      logging.exception('Error processing image %s: %s', uri, str(e))\n",
    "      return\n",
    "\n",
    "    # Convert to desired format and output.\n",
    "    output = cStringIO.StringIO()\n",
    "    img.save(output, 'jpeg')\n",
    "    image_bytes = output.getvalue()\n",
    "    yield uri, label_id, image_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Extract features from images\n",
    "\n",
    "Embeds image bytes and labels, stores them in tensorflow.Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ExtractTFExampleFromImagesDoFn(beam.DoFn):\n",
    "  \"\"\"Embeds image bytes and labels, stores them in tensorflow.Example.\n",
    "\n",
    "  (uri, label_ids, image_bytes) -> (tensorflow.Example).\n",
    "\n",
    "  Output proto contains 'label', 'image_uri' and 'embedding'.\n",
    "  The 'embedding' is calculated by feeding image into input layer of image\n",
    "  neural network and reading output of the bottleneck layer of the network.\n",
    "\n",
    "  Attributes:\n",
    "    image_graph_uri: an uri to gcs bucket where serialized image graph is\n",
    "                     stored.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, checkpoint_path):\n",
    "    import tensorflow as tf\n",
    "    self._tf = tf\n",
    "    self._tf_train = tf.train\n",
    "    self.tf_session = None\n",
    "    self.graph = None\n",
    "    self.preprocess_graph = None\n",
    "    self._checkpoint_path = checkpoint_path\n",
    "\n",
    "  def start_bundle(self, context=None):\n",
    "    # There is one tensorflow session per instance of TFExampleFromImageDoFn.\n",
    "    # The same instance of session is re-used between bundles.\n",
    "    # Session is closed by the destructor of Session object, which is called\n",
    "    # when instance of TFExampleFromImageDoFn() is destructed.\n",
    "    import mltoolbox.image.classification._preprocess as preprocess\n",
    "    if not self.graph:\n",
    "      self.graph = self._tf.Graph()\n",
    "      self.tf_session = self._tf.InteractiveSession(graph=self.graph)\n",
    "      with self.graph.as_default():\n",
    "        self.preprocess_graph = preprocess.EmbeddingsGraph(self.tf_session, self._checkpoint_path)\n",
    "\n",
    "  def finish_bundle(self, context=None):\n",
    "    if self.tf_session is not None:\n",
    "      self.tf_session.close()\n",
    "\n",
    "  def process(self, element):\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "      return self._tf_train.Feature(bytes_list=self._tf_train.BytesList(value=value))\n",
    "\n",
    "    def _float_feature(value):\n",
    "      return self._tf_train.Feature(float_list=self._tf_train.FloatList(value=value))\n",
    "\n",
    "    uri, label_id, image_bytes = element\n",
    "\n",
    "    try:\n",
    "      embedding = self.preprocess_graph.calculate_embedding(image_bytes)\n",
    "    except self._tf.errors.InvalidArgumentError as e:\n",
    "      logging.warning('Could not encode an image from %s: %s', uri, str(e))\n",
    "      return\n",
    "\n",
    "    features = self._tf_train.Features(\n",
    "      feature={\n",
    "        'image_uri': _bytes_feature([str(uri)]),\n",
    "        'embedding': _float_feature(embedding.ravel().tolist())\n",
    "      })\n",
    "    example = self._tf_train.Example(features=features)\n",
    "    example.features.feature['label'].int64_list.value.append(label_id)\n",
    "\n",
    "    yield example\n",
    "    \n",
    "class ExtractFeatures(beam.PTransform):\n",
    "  \"\"\"Load labels and labeled images from GCS.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super(ExtractFeatures, self).__init__('ExtractFeatures')\n",
    "    self._checkpoint = 'gs://cloud-ml-data/img/flower_photos/inception_v3_2016_08_28.ckpt'\n",
    "\n",
    "  def expand(self, labeled_images):\n",
    "    return (labeled_images |\n",
    "            'ConvertImagesToJpeg' >> beam.ParDo(ConvertImagesToJpegDoFn()) |\n",
    "            'ExtractTFExampleFromImages' >> beam.ParDo(ExtractTFExampleFromImagesDoFn(self._checkpoint)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 3 - Create training and test data\n",
    "TODO : Write the exercise description. Point attendees to the documentation of PartitionFn.\n",
    "\n",
    "TODO : Make sure that all classes are equelly represented in the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TrainEvalSplitPartitionFn(beam.PartitionFn):\n",
    "  \"\"\"Split train and eval data.\"\"\"\n",
    "  def partition_for(self, element, num_partitions):\n",
    "    import random\n",
    "    # TODO : write what needs to be done in the exercise\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "To see the solution please display the code in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainEvalSplitPartitionFn(beam.PartitionFn):\n",
    "  \"\"\"Split train and eval data.\"\"\"\n",
    "  def partition_for(self, element, num_partitions):\n",
    "    import random\n",
    "    return 1 if random.random() > 0.7 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write features to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ExampleProtoCoder(beam.coders.Coder):\n",
    "  \"\"\"A coder to encode and decode TensorFlow Example objects.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    import tensorflow as tf\n",
    "    self._tf_train = tf.train\n",
    "\n",
    "  def encode(self, example_proto):\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "  def decode(self, serialized_str):\n",
    "    example = self._tf_train.Example()\n",
    "    example.ParseFromString(serialized_str)\n",
    "    return example\n",
    "\n",
    "\n",
    "class SaveFeatures(beam.PTransform):\n",
    "  \"\"\"Save Features in a TFRecordIO format.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, file_path_prefix):\n",
    "    super(SaveFeatures, self).__init__('SaveFeatures')\n",
    "    self._file_path_prefix = file_path_prefix\n",
    "\n",
    "  def expand(self, features):\n",
    "    return (features |\n",
    "            'Write features' >> tfrecordio.WriteToTFRecord(file_path_prefix=self._file_path_prefix,\n",
    "                                                           file_name_suffix='.tfrecord.gz',\n",
    "                                                           coder=ExampleProtoCoder()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the pipeline\n",
    "\n",
    "Boilerplate code to create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_pipeline(train_dataset, output_dir, project, pipeline_option):\n",
    "  \"\"\"Create the Dataflow pipeline.\"\"\"\n",
    "  import csv\n",
    "  \n",
    "  job_name = ('preprocess-image-classification-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "  options = {\n",
    "      'staging_location': os.path.join(output_dir, 'tmp', 'staging'),\n",
    "      'temp_location': os.path.join(output_dir, 'tmp'),\n",
    "      'job_name': job_name,\n",
    "      'project': project,\n",
    "      'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "      'no_save_main_session': True\n",
    "  }\n",
    "  if pipeline_option is not None:\n",
    "    options.update(pipeline_option)\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "  \n",
    "  p = beam.Pipeline('DataflowRunner', options=opts)\n",
    "  #p = beam.Pipeline('DirectRunner', options=opts) \n",
    "  \n",
    "  # Load the images from Cloud Storage and extract Inception features from them\n",
    "  labeled_images, labels = p | 'PrepareTrainingData' >> PrepareTrainingData(train_dataset)\n",
    "  preprocessed_data = labeled_images | 'ExtractFeatures' >> ExtractFeatures()\n",
    "  \n",
    "  # Create the training and evaluation datasets\n",
    "  training_data, eval_data = preprocessed_data | 'CreateTrainingAndEvalDatasets' >> beam.Partition(TrainEvalSplitPartitionFn(), 2)\n",
    "  \n",
    "  # Write the training and evaluation datasets on Clud Storage\n",
    "  output_train_path = os.path.join(output_dir, job_name, 'train')\n",
    "  output_eval_path = os.path.join(output_dir, job_name, 'eval')\n",
    "  output_labels_file = os.path.join(output_dir, job_name, 'labels')\n",
    "  output_latest_file = os.path.join(output_dir, 'latest')\n",
    "  train_save = training_data | 'WriteTrainingData' >> SaveFeatures(output_train_path)\n",
    "  eval_save = eval_data | 'WriteEvalData' >> SaveFeatures(output_eval_path)\n",
    "  labels_save = labels | 'WriteLabels' >> WriteToText(output_labels_file, shard_name_template='')\n",
    "\n",
    "  # Write the checkpoint for the next step\n",
    "  ([eval_save, train_save, labels_save] |\n",
    "   'WaitEndOfWrite' >> beam.Flatten() |\n",
    "   'CombineWriteResults' >> beam.transforms.combiners.Sample.FixedSizeGlobally(1) |\n",
    "   'JobNameToMap' >> beam.Map(lambda path: job_name) |\n",
    "   'WriteJobNameToLatest' >> beam.io.textio.WriteToText(output_latest_file, shard_name_template=''))\n",
    "  \n",
    "  return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run the pipeline \n",
    "Run the pipeline and wait until it finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run 'Common.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train_set = 'gs://candies-ml/dataset/metadata/train_candies560.csv'\n",
    "train_dataset = 'gs://candies-ml/dataset/metadata/train_candies16.csv'\n",
    "pipeline_runner = PipelineRunner(train_dataset, preprocess_dir, project_id, pipeline_options={'num_workers': 2})\n",
    "#pipeline_runner = PipelineRunner(train_dataset, preprocess_dir, project_id)\n",
    "pipeline_runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
